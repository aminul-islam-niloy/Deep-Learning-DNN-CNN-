{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Customized Transfer Learning (TL) Method for handwritten digit classification using VGG16 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part (a): Generate a TL Model with VGG16\n",
    "Freezing Fully-Connected (FC) and Output Layers of the VGG16 model.\n",
    "Set a new FC layer and an output layer for MNIST digit classification.\n",
    "Initialize the model with pre-trained weights on ImageNet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Normalize the dataset and resize to 32x32\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "x_train_resized = tf.image.resize(x_train[..., np.newaxis], (32, 32))\n",
    "x_test_resized = tf.image.resize(x_test[..., np.newaxis], (32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert single channel grayscale to 3-channel for VGG16 compatibility\n",
    "x_train_resized = np.repeat(x_train_resized, 3, axis=-1)\n",
    "x_test_resized = np.repeat(x_test_resized, 3, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the VGG16 model without the top layers, freezing its convolutional layers\n",
    "vgg16_base = VGG16(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n",
    "for layer in vgg16_base.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add new fully-connected layers\n",
    "x = Flatten()(vgg16_base.output)\n",
    "x = Dense(512, activation='relu')(x)  # Fully-connected layer with 512 units\n",
    "output = Dense(10, activation='softmax')(x)  # Output layer for 10 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the new model\n",
    "custom_vgg16_model = Model(inputs=vgg16_base.input, outputs=output)\n",
    "custom_vgg16_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the customized VGG16 model\n",
    "custom_vgg16_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=10,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen.fit(x_train_resized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train on original MNIST dataset\n",
    "history_original = custom_vgg16_model.fit(x_train_resized, y_train, validation_split=0.1, epochs=10, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train on augmented MNIST dataset\n",
    "history_augmented = custom_vgg16_model.fit(datagen.flow(x_train_resized, y_train, batch_size=32),\n",
    "                                           validation_data=(x_test_resized, y_test), epochs=10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate on test data\n",
    "test_loss_orig, test_acc_orig = custom_vgg16_model.evaluate(x_test_resized, y_test)\n",
    "print(f\"Test accuracy on original data: {test_acc_orig:.4f}\")\n",
    "\n",
    "# Evaluate on augmented test data\n",
    "test_loss_aug, test_acc_aug = custom_vgg16_model.evaluate(x_test_resized, y_test)\n",
    "print(f\"Test accuracy on augmented data: {test_acc_aug:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot accuracy comparison\n",
    "plt.plot(history_original.history['accuracy'], label='Original Training Accuracy')\n",
    "plt.plot(history_original.history['val_accuracy'], label='Original Validation Accuracy')\n",
    "plt.plot(history_augmented.history['accuracy'], label='Augmented Training Accuracy')\n",
    "plt.plot(history_augmented.history['val_accuracy'], label='Augmented Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy of VGG16 Models')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
